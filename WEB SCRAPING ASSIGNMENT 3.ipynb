{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementClickInterceptedException,ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\Project_flip_robo\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product vertical\n",
    "from www.amazon.in. The product verticals to be searched will be taken as input from user.\n",
    "For e.g. If user input is ‘guitar’. Then search for guitars.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product you want to search : Keyboard\n"
     ]
    }
   ],
   "source": [
    "user_inp = input('Enter the product you want to search : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys(user_inp)                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]/span/input')       # Locating search_button by xpath\n",
    "search_button.click()                                                                # Clicking the button to start search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages\n",
    "of your search results and save it in a dataframe and csv. In case if any product vertical has\n",
    "less than 3 pages in search results then scrape all the products available under that product\n",
    "vertical. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of\n",
    "Ratings\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\"\n",
    "and “Product URL”. In case, if any of the details are missing for any of the product then\n",
    "replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product={}\n",
    "Product['Brand']=[]\n",
    "Product['Name']=[]\n",
    "Product['Rating']=[]\n",
    "Product['No_of_Rating']=[]\n",
    "Product['Price']=[]\n",
    "Product['Return_Exchange']=[]\n",
    "Product['Expected Delivery']=[] \n",
    "Product['Availability']=[]\n",
    "Product['Other Details']=[]\n",
    "Product['URL']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "start_page = 0\n",
    "end_page = 2\n",
    "urls = []\n",
    "for page in range(start_page,end_page+1):\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')     \n",
    "            if url[0:4]=='http':              \n",
    "                urls.append(url)               \n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        next_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')     \n",
    "        if next_button.text == 'Next→':                                            \n",
    "            next_button.click()                                                   \n",
    "            time.sleep(3)                                                        \n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL =  https://www.amazon.in/gp/slredirect/picassoRedirect.html/ref=pa_sp_atf_next_aps_sr_pg2_1?ie=UTF8&adId=A02517091J927TZBP946Z&url=%2FQuantum-7307-Multimedia-Keyboard-Black%2Fdp%2FB00OTFCVAE%2Fref%3Dsr_1_17_sspa%3Fdchild%3D1%26keywords%3DKeyboard%26qid%3D1612684122%26sr%3D8-17-spons%26psc%3D1&qualifier=1612684732&id=4595502497594218&widgetName=sp_atf_next\n",
      "Scraping URL =  https://www.amazon.in/gp/slredirect/picassoRedirect.html/ref=pa_sp_atf_next_aps_sr_pg2_1?ie=UTF8&adId=A09428613GBAG7II8XI53&url=%2FLive-Tech-April-Keyboard-Noiseless%2Fdp%2FB08L85XP4R%2Fref%3Dsr_1_18_sspa%3Fdchild%3D1%26keywords%3DKeyboard%26qid%3D1612684122%26sr%3D8-18-spons%26psc%3D1&qualifier=1612684732&id=4595502497594218&widgetName=sp_atf_next\n",
      "Scraping URL =  https://www.amazon.in/Laprite-Keyboard-Lenovo-Protective-Skin-Transparent/dp/B08VGPHHPN/ref=sr_1_19?dchild=1&keywords=Keyboard&qid=1612684122&sr=8-19\n",
      "Scraping URL =  https://www.amazon.in/Laprite-Premium-Keyboard-Predator-Helios/dp/B08VGRTSD8/ref=sr_1_20?dchild=1&keywords=Keyboard&qid=1612684122&sr=8-20\n"
     ]
    }
   ],
   "source": [
    "for url in urls[:4]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    print(\"Scraping URL = \", url)\n",
    "    #time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        brand = driver.find_element_by_xpath('//a[@id=\"bylineInfo\"]')      # Extracting Brand from xpath\n",
    "        Product['Brand'].append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Product['Brand'].append('-')\n",
    "    \n",
    "    try:\n",
    "        name = driver.find_element_by_xpath('//h1[@id=\"title\"]/span')      # Extracting Name from xpath\n",
    "        Product['Name'].append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Product['Name'].append('-')\n",
    "    \n",
    "    try:\n",
    "        rating = driver.find_element_by_xpath('//span[@id=\"acrPopover\"]')  # Extracting Ratings from xpath\n",
    "        Product['Rating'].append(rating.get_attribute(\"title\"))\n",
    "    except NoSuchElementException:\n",
    "        Product['Rating'].append('-')\n",
    "    \n",
    "    try:\n",
    "        n_rating = driver.find_element_by_xpath('//a[@id=\"acrCustomerReviewLink\"]/span')     # Extracting no. of Ratings from xpath\n",
    "        Product['No_of_Rating'].append(n_rating.text)\n",
    "    except NoSuchElementException:\n",
    "        Product['No_of_Rating'].append('-')\n",
    "    \n",
    "    try:\n",
    "        price = driver.find_element_by_xpath('//span[@id=\"priceblock_ourprice\"]')            # Extracting Price from xpath\n",
    "        Product['Price'].append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        Product['Price'].append('-')\n",
    "    try:                                                                                     # Extracting Return/Exchange policy from xpath\n",
    "        ret = driver.find_element_by_xpath('//div[@data-name=\"RETURNS_POLICY\"]/span/div[2]/a')\n",
    "        Product['Return_Exchange'].append(ret.text)\n",
    "    except NoSuchElementException:\n",
    "        Product['Return_Exchange'].append('-')\n",
    "    try:\n",
    "        delivry = driver.find_element_by_xpath('//div[@id=\"ddmDeliveryMessage\"]/b')         # Extracting Expected Delivery from xpath\n",
    "        Product['Expected Delivery'].append(delivry.text)\n",
    "    except NoSuchElementException:\n",
    "        Product['Expected Delivery'].append('-')\n",
    "    \n",
    "    try:\n",
    "        avl = driver.find_element_by_xpath('//div[@id=\"availability\"]/span')                # Extracting Availability from xpath\n",
    "        Product['Availability'].append(avl.text)\n",
    "    except NoSuchElementException:\n",
    "        Product['Availability'].append('-')\n",
    "    \n",
    "    try:                                                                                    # Extracting Other Details from xpath\n",
    "        dtls = driver.find_element_by_xpath('//ul[@class=\"a-unordered-list a-vertical a-spacing-mini\"]')\n",
    "        Product['Other Details'].append('  ||  '.join(dtls.text.split('\\n')))\n",
    "    except NoSuchElementException:\n",
    "        Product['Other Details'].append('-')\n",
    "    \n",
    "    Product['URL'].append(url)                                                            # Saving url\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>No_of_Rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>Return_Exchange</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Other Details</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visit the Quantum Store</td>\n",
       "      <td>Quantum QHM7307 Mini Spill-Resistant USB Wired...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>420 ratings</td>\n",
       "      <td>₹ 349.00</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Tuesday, Feb 9</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Long life with life span of 10 million times  ...</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visit the Live Tech Store</td>\n",
       "      <td>Live Tech April Stylish USB Keyboard Wired Wat...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>17 ratings</td>\n",
       "      <td>₹ 385.00</td>\n",
       "      <td>Non Returnable</td>\n",
       "      <td>Tuesday, Feb 9</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>STANDARD LAYOUT :: The keyboard's full layout ...</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brand: Laprite</td>\n",
       "      <td>Laprite Keyboard Cover Skin for 2020 Lenovo Le...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Sunday, Feb 14</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>DURABLE DESIGN- made with premium engineering ...</td>\n",
       "      <td>https://www.amazon.in/Laprite-Keyboard-Lenovo-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brand: Laprite</td>\n",
       "      <td>Laprite Premium Keyboard Cover Skin for Acer P...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>₹ 399.00</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Sunday, Feb 14</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Every key is individually moulded and speciall...</td>\n",
       "      <td>https://www.amazon.in/Laprite-Premium-Keyboard...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Brand  \\\n",
       "0    Visit the Quantum Store   \n",
       "1  Visit the Live Tech Store   \n",
       "2             Brand: Laprite   \n",
       "3             Brand: Laprite   \n",
       "\n",
       "                                                Name              Rating  \\\n",
       "0  Quantum QHM7307 Mini Spill-Resistant USB Wired...  3.5 out of 5 stars   \n",
       "1  Live Tech April Stylish USB Keyboard Wired Wat...  4.1 out of 5 stars   \n",
       "2  Laprite Keyboard Cover Skin for 2020 Lenovo Le...                   -   \n",
       "3  Laprite Premium Keyboard Cover Skin for Acer P...                   -   \n",
       "\n",
       "  No_of_Rating     Price     Return_Exchange Expected Delivery Availability  \\\n",
       "0  420 ratings  ₹ 349.00  7 Days Replacement    Tuesday, Feb 9    In stock.   \n",
       "1   17 ratings  ₹ 385.00      Non Returnable    Tuesday, Feb 9    In stock.   \n",
       "2            -         -  7 Days Replacement    Sunday, Feb 14    In stock.   \n",
       "3            -  ₹ 399.00  7 Days Replacement    Sunday, Feb 14    In stock.   \n",
       "\n",
       "                                       Other Details  \\\n",
       "0  Long life with life span of 10 million times  ...   \n",
       "1  STANDARD LAYOUT :: The keyboard's full layout ...   \n",
       "2  DURABLE DESIGN- made with premium engineering ...   \n",
       "3  Every key is individually moulded and speciall...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "1  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "2  https://www.amazon.in/Laprite-Keyboard-Lenovo-...  \n",
       "3  https://www.amazon.in/Laprite-Premium-Keyboard...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_df = pd.DataFrame.from_dict(Product)\n",
    "Product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Write a python program to access the search bar and search button on images.google.com and\n",
    "scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.google.com/imghp?hl=en\")\n",
    "soup= BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search button\n",
    "search_button=driver.find_element_by_xpath(\"//*[@id='sbtc']/button/div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_product=driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\")\n",
    "search_field_product.send_keys(\"fruits\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start scrolling to generate more images on the page...\n"
     ]
    }
   ],
   "source": [
    "print(\"start scrolling to generate more images on the page...\")\n",
    "# 500 time we scroll down by 10000 in order to generate more images on the website\n",
    "for _ in range(500):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgResults = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls = []\n",
    "img_data = []\n",
    "for i in imgResults:\n",
    "    source= i.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\USER\\Desktop\\Project_flip_robo\\image\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_product=driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\")\n",
    "search_field_product.send_keys(\"cars\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start scrolling to generate more images on the page...\n"
     ]
    }
   ],
   "source": [
    "print(\"start scrolling to generate more images on the page...\")\n",
    "# 500 time we scroll down by 10000 in order to generate more images on the website\n",
    "for _ in range(500):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgResults = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls = []\n",
    "img_data = []\n",
    "for i in imgResults:\n",
    "    source= i.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\USER\\Desktop\\Project_flip_robo\\image\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_product=driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\")\n",
    "search_field_product.send_keys(\"Machine Learning\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start scrolling to generate more images on the page...\n"
     ]
    }
   ],
   "source": [
    "print(\"start scrolling to generate more images on the page...\")\n",
    "# 500 time we scroll down by 10000 in order to generate more images on the website\n",
    "for _ in range(500):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgResults = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls = []\n",
    "img_data = []\n",
    "for i in imgResults:\n",
    "    source= i.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\USER\\Desktop\\Project_flip_robo\\image\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on\n",
    "www.flipkart.com and scrape following details for all the search results displayed on 1st page.\n",
    "Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”,\n",
    "“Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display\n",
    "Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”.\n",
    "Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe\n",
    "and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')                      # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_button\n",
    "search_button=driver.find_element_by_xpath(\"//*[@id='container']/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_product=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_field_product.send_keys(\"redmi note 9 pro\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls of phones coming on 1st page\n",
    "Url = []\n",
    "urls = driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]')\n",
    "for url in urls:\n",
    "    Url.append(url.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Smartphone_dict = {}\n",
    "Smartphone_dict[\"Brand\"] = []\n",
    "Smartphone_dict[\"Smartphone\"] = []\n",
    "Smartphone_dict[\"Price\"]=[]\n",
    "Smartphone_dict[\"Colour\"] = []\n",
    "Smartphone_dict[\"RAM\"] = []\n",
    "Smartphone_dict[\"Storage(ROM)\"] = []\n",
    "Smartphone_dict[\"Primary Camera\"] = []\n",
    "Smartphone_dict[\"Secondary Camera\"] = []\n",
    "Smartphone_dict[\"Display Size\"] = []\n",
    "Smartphone_dict[\"Display Resolution\"] = []\n",
    "Smartphone_dict[\"Processor\"] = []\n",
    "Smartphone_dict[\"Processor Cores\"] = []\n",
    "Smartphone_dict[\"Battery Capacity\"] = []\n",
    "Smartphone_dict[\"Battery Type\"] = []\n",
    "Smartphone_dict[\"URL\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-interstellar-black-128-gb/p/itm0418537d115ba?pid=MOBFUZYNSYP64TQK&lid=LSTMOBFUZYNSYP64TQKAQNQ5Q&marketplace=FLIPKART&srno=s_1_1&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFUZYNSYP64TQK.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-champagne-gold-128-gb/p/itm812ce2c5ee97d?pid=MOBFVN5JQRXMWYSZ&lid=LSTMOBFVN5JQRXMWYSZG8DK53&marketplace=FLIPKART&srno=s_1_2&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFVN5JQRXMWYSZ.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-interstellar-black-64-gb/p/itm7dffdce5d6370?pid=MOBFUFTCKCPHZTQX&lid=LSTMOBFUFTCKCPHZTQXROREHT&marketplace=FLIPKART&srno=s_1_3&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFUFTCKCPHZTQX.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-champagne-gold-128-gb/p/itma8d25ca0b4c91?pid=MOBFV99GTFHDSKGW&lid=LSTMOBFV99GTFHDSKGWYXWGYF&marketplace=FLIPKART&srno=s_1_4&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFV99GTFHDSKGW.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-interstellar-black-128-gb/p/itmb47f59cf8b7c3?pid=MOBFRWZN9WHWZKZJ&lid=LSTMOBFRWZN9WHWZKZJNSFBC5&marketplace=FLIPKART&srno=s_1_5&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFRWZN9WHWZKZJ.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-glacier-white-128-gb/p/itm1f4b8a12f5710?pid=MOBFRWZNDTQSCQCB&lid=LSTMOBFRWZNDTQSCQCBB43JPZ&marketplace=FLIPKART&srno=s_1_6&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFRWZNDTQSCQCB.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-aurora-blue-128-gb/p/itm63ebdd2c2bff4?pid=MOBFU84NFQZTZBBZ&lid=LSTMOBFU84NFQZTZBBZ3KNLZH&marketplace=FLIPKART&srno=s_1_7&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFU84NFQZTZBBZ.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-champagne-gold-64-gb/p/itma6155aa76e6be?pid=MOBFV99GD4BZRXFD&lid=LSTMOBFV99GD4BZRXFDF8PVPV&marketplace=FLIPKART&srno=s_1_8&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFV99GD4BZRXFD.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-aurora-blue-128-gb/p/itm6306e1d4476e3?pid=MOBFU84TNRP5YDMX&lid=LSTMOBFU84TNRP5YDMXU7TXIM&marketplace=FLIPKART&srno=s_1_9&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFU84TNRP5YDMX.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-glacier-white-64-gb/p/itma84d60532d415?pid=MOBFPZXU9QDDSKNU&lid=LSTMOBFPZXU9QDDSKNULGXZWA&marketplace=FLIPKART&srno=s_1_10&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFPZXU9QDDSKNU.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-aurora-blue-128-gb/p/itma84d60532d415?pid=MOBFPZXUYDHUHNNN&lid=LSTMOBFPZXUYDHUHNNNX1CXVJ&marketplace=FLIPKART&srno=s_1_11&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFPZXUYDHUHNNN.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-6-pro-blue-64-gb/p/itmf93aa56274a88?pid=MOBFAJB4RSWTEYJJ&lid=LSTMOBFAJB4RSWTEYJJRGGDKK&marketplace=FLIPKART&srno=s_1_12&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFAJB4RSWTEYJJ.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-5-pro-black-64-gb/p/itmf2fc3qjzftfch?pid=MOBF28FTKDWY5EHE&lid=LSTMOBF28FTKDWY5EHEWLTAYU&marketplace=FLIPKART&srno=s_1_13&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBF28FTKDWY5EHE.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-8-pro-shadow-black-128-gb/p/itm014bee372e2a7?pid=MOBFHFGFPAMSCEA4&lid=LSTMOBFHFGFPAMSCEA4YJAVWO&marketplace=FLIPKART&srno=s_1_14&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFHFGFPAMSCEA4.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-interstellar-black-64-gb/p/itma84d60532d415?pid=MOBFPZXUJHMYCBFK&lid=LSTMOBFPZXUJHMYCBFKBIUYL7&marketplace=FLIPKART&srno=s_1_15&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFPZXUJHMYCBFK.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-champagne-gold-64-gb/p/itma84d60532d415?pid=MOBFVSQPKVB8QQJ6&lid=LSTMOBFVSQPKVB8QQJ6D6C9BD&marketplace=FLIPKART&srno=s_1_16&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFVSQPKVB8QQJ6.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-aurora-blue-128-gb/p/itma84d60532d415?pid=MOBFUUN6B5XSFYXT&lid=LSTMOBFUUN6B5XSFYXTKNITGD&marketplace=FLIPKART&srno=s_1_17&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFUUN6B5XSFYXT.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-glacier-white-128-gb/p/itma84d60532d415?pid=MOBFUSGFZDDJHWMG&lid=LSTMOBFUSGFZDDJHWMGPCFWFR&marketplace=FLIPKART&srno=s_1_18&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFUSGFZDDJHWMG.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-interstellar-black-128-gb/p/itma84d60532d415?pid=MOBFPZXUT5FX9GUH&lid=LSTMOBFPZXUT5FX9GUHFOBFFT&marketplace=FLIPKART&srno=s_1_19&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFPZXUT5FX9GUH.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-aurora-blue-64-gb/p/itma84d60532d415?pid=MOBFPZXUDUPUKZF6&lid=LSTMOBFPZXUDUPUKZF6YA8Q1S&marketplace=FLIPKART&srno=s_1_20&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFPZXUDUPUKZF6.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-glacier-white-128-gb/p/itm7651b521a521f?pid=MOBFTGMCRZV8A6EK&lid=LSTMOBFTGMCRZV8A6EKCJWKIM&marketplace=FLIPKART&srno=s_1_21&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFTGMCRZV8A6EK.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-champagne-gold-128-gb/p/itma84d60532d415?pid=MOBFVNYYZZ6AJT44&lid=LSTMOBFVNYYZZ6AJT44HSHR2N&marketplace=FLIPKART&srno=s_1_22&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFVNYYZZ6AJT44.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-glacier-white-128-gb/p/itm0d3be5fb6aa0b?pid=MOBFUUDCNZER6EW8&lid=LSTMOBFUUDCNZER6EW88EIQRY&marketplace=FLIPKART&srno=s_1_23&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFUUDCNZER6EW8.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n",
      "Scraping URL =  https://www.flipkart.com/redmi-note-9-pro-max-interstellar-black-128-gb/p/itm5319b927846d8?pid=MOBFU84ZJ65P6PTU&lid=LSTMOBFU84ZJ65P6PTUYQS6MY&marketplace=FLIPKART&srno=s_1_24&otracker=search&otracker1=search&fm=SEARCH&iid=0316d5e1-8ca6-416d-a62e-78153c0f7c79.MOBFU84ZJ65P6PTU.SEARCH&ppt=sp&ppn=sp&ssid=ve0zjdcr740000001612700076101&qH=2eeee788c4b5011c\n"
     ]
    }
   ],
   "source": [
    "# Scraping data from each url\n",
    "for url in flip_urls\n",
    "    driver.get(url)    # Saving url                                                     \n",
    "    print(\"Scraping URL = \", url)\n",
    "    Smartphone_dict[\"URL\"].append(url)                                                          # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        read_more = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _1FH0tX\"]')     # Button for expanding the specs\n",
    "        read_more.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"Exception Occured. Moving to next page\")\n",
    "    \n",
    "    try:\n",
    "        brand = driver.find_element_by_xpath('//span[@class=\"B_NuCI\"]')      # Extracting Brand from xpath\n",
    "        Smartphone_dict[\"Brand\"].append(brand.text.split()[0])\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Brand\"].append('-')\n",
    "        \n",
    "    try:\n",
    "        price = driver.find_element_by_xpath('//div[@class=\"_30jeq3 _16Jk6d\"]')      # Extracting Brand from xpath\n",
    "        Smartphone_dict[\"Smartphone\"].append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Smartphone\"].append('-')\n",
    "        \n",
    "    try:\n",
    "        name = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[3]/td[2]/ul/li')      # Extracting Brand from xpath\n",
    "        Smartphone_dict[\"Price\"].append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Price\"].append('-')\n",
    "    \n",
    "    try:\n",
    "        color = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[4]/td[2]/ul/li')      # Extracting Name from xpath\n",
    "        Smartphone_dict[\"Colour\"].append(color.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Colour\"].append('-')\n",
    "    \n",
    "    try:\n",
    "        disp_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/div')\n",
    "        if disp_chk.text != \"Display Features\" : raise NoSuchElementException\n",
    "        disp_size = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/table[1]/tbody/tr[1]/td[2]/ul/li')  # Extracting Ratings from xpath\n",
    "        Smartphone_dict[\"Display Size\"].append(disp_size.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Display Size\"].append('-')\n",
    "    \n",
    "    try:\n",
    "        disp_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/div')\n",
    "        if disp_chk.text != \"Display Features\" : raise NoSuchElementException\n",
    "        disp_res = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/table[1]/tbody/tr[2]/td[2]/ul/li')     # Extracting no. of Ratings from xpath\n",
    "        Smartphone_dict[\"Display Resolution\"].append(disp_res.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Display Resolution\"].append('-')\n",
    "    \n",
    "    try:\n",
    "        pro_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[2]/td[1]')\n",
    "        if pro_chk.text != \"Processor Type\" : raise NoSuchElementException\n",
    "        processor = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[2]/td[2]/ul/li')   # Extracting Price from xpath\n",
    "        Smartphone_dict[\"Processor\"].append(processor.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Processor\"].append('-')\n",
    "    \n",
    "    try:                                                                                     # Extracting Return/Exchange policy from xpath\n",
    "        core_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[3]/td[1]')\n",
    "        if core_chk.text != \"Processor Core\" :\n",
    "            core_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[2]/td[1]')\n",
    "            if core_chk.text != \"Processor Core\" : \n",
    "                raise NoSuchElementException\n",
    "            else :\n",
    "                cores = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[2]/td[2]/ul/li')\n",
    "        else :\n",
    "            cores = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[3]/td[2]/ul/li')\n",
    "        Smartphone_dict[\"Processor Cores\"].append(cores.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Processor Cores\"].append('-')\n",
    "    \n",
    "    try:\n",
    "        rom = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][4]/table[1]/tbody/tr[1]/td[2]/ul/li')         # Extracting Expected Delivery from xpath\n",
    "        Smartphone_dict[\"Storage(ROM)\"].append(rom.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Storage(ROM)\"].append('-')\n",
    "    \n",
    "    try:\n",
    "        ram = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][4]/table[1]/tbody/tr[2]/td[2]/ul/li')                # Extracting Availability from xpath\n",
    "        Smartphone_dict[\"RAM\"].append(ram.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"RAM\"].append('-')\n",
    "    \n",
    "    try:                                                                                    # Extracting Other Details from xpath\n",
    "        pri_cam = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[2]/td[2]/ul/li')\n",
    "        Smartphone_dict[\"Primary Camera\"].append(pri_cam.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Primary Camera\"].append('-')\n",
    "    \n",
    "    try:                                                                                    # Extracting Other Details from xpath\n",
    "        cam_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[6]/td[1]')\n",
    "        if cam_chk != \"Secondary Camera\" : \n",
    "            if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[5]/td[1]').text == \"Secondary Camera\":\n",
    "                sec_cam = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[5]/td[2]/ul/li')\n",
    "            else :\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            sec_cam = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[6]/td[2]/ul/li')\n",
    "        Smartphone_dict[\"Secondary Camera\"].append(sec_cam.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Secondary Camera\"].append('-')\n",
    "        \n",
    "    try:\n",
    "        if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/div').text != \"Battery & Power Features\" :\n",
    "            if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/div').text == \"Battery & Power Features\" :\n",
    "                bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr/td[1]')\n",
    "                if bat_chk.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_cap = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr/td[2]/ul/li')                # Extracting Availability from xpath\n",
    "            elif driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/div').text == \"Battery & Power Features\" :\n",
    "                bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr/td[1]')\n",
    "                if bat_chk.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_cap = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr/td[2]/ul/li')\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr/td[1]')\n",
    "            if bat_chk.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "            bat_cap = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr/td[2]/ul/li')                # Extracting Availability from xpath\n",
    "        Smartphone_dict[\"Battery Capacity\"].append(bat_cap.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Battery Capacity\"].append('-')\n",
    "    \n",
    "    try:\n",
    "        if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/div').text != \"Battery & Power Features\" :\n",
    "            if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/div').text == \"Battery & Power Features\" :\n",
    "                bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr[2]/td[1]')\n",
    "                if bat_chk.text != \"Battery Type\" : raise NoSuchElementException\n",
    "                bat_typ = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "            elif driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/div').text == \"Battery & Power Features\" :\n",
    "                bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr[2]/td[1]')\n",
    "                if bat_chk.text != \"Battery Type\" : raise NoSuchElementException\n",
    "                bat_typ = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr[2]/td[1]')\n",
    "            if bat_chk.text != \"Battery Type\" : raise NoSuchElementException\n",
    "            bat_typ = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr[2]/td[2]/ul/li')                # Extracting Availability from xpath\n",
    "        Smartphone_dict[\"Battery Type\"].append(bat_typ.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphone_dict[\"Battery Type\"].append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39 39 38 39 38 38 39 39 39 39 38 38\n"
     ]
    }
   ],
   "source": [
    "print(len(Smartphone_dict[\"Brand\"]), \n",
    "len(Smartphone_dict[\"Smartphone\"]), \n",
    "len(Smartphone_dict[\"Price\"]), \n",
    "len(Smartphone_dict[\"URL\"]),\n",
    "len(Smartphone_dict[\"RAM\"]) ,\n",
    "len(Smartphone_dict[\"Colour\"]) ,\n",
    "len(Smartphone_dict[\"Storage(ROM)\"]),\n",
    "len(Smartphone_dict[\"Primary Camera\"]),\n",
    "len(Smartphone_dict[\"Display Size\"]),\n",
    "len(Smartphone_dict[\"Display Resolution\"]),\n",
    "len(Smartphone_dict[\"Processor\"]),\n",
    "len(Smartphone_dict[\"Processor Cores\"]),\n",
    "len(Smartphone_dict[\"Battery Capacity\"]),\n",
    "len(Smartphone_dict[\"Battery Type\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-0d427d9d3eb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSmartphone_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1245\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"only recognize index or columns for orient\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         ]\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(Smartphone_dict)\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5.Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on\n",
    "google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.google.com/maps/@21.125498,81.914063,5z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter City Name : Kolkata\n"
     ]
    }
   ],
   "source": [
    "city = input('Enter City Name : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_button\n",
    "search_button=driver.find_element_by_xpath(\"//*[@id='searchbox-searchbutton']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_city=driver.find_element_by_xpath(\"//input[@class='tactile-searchbox-input']\")\n",
    "search_field_city.send_keys(city)\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Extracted:  https://www.google.com/maps/place/Kolkata,+West+Bengal/@22.6757521,88.0495215,10z/data=!3m1!4b1!4m5!3m4!1s0x39f882db4908f667:0x43e330e68f6c2cbc!8m2!3d22.572646!4d88.363895\n",
      "Latitude = 22.6757521, Longitude = 88.0495215\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    url_string = driver.current_url\n",
    "    print(\"URL Extracted: \", url_string)\n",
    "    lat_lng = re.findall(r'@(.*)data',url_string)\n",
    "    if len(lat_lng):\n",
    "        lat_lng_list = lat_lng[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            lat = lat_lng_list[0]\n",
    "            lng = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(lat, lng))\n",
    "\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6.Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 –\n",
    "September 20) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://trak.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element_by_xpath('//li[@id=\"menu-item-51510\"]/a').get_attribute('href')\n",
    "driver.get(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_dict = {}\n",
    "fund_dict['Date'] = []\n",
    "fund_dict['Startup Name'] = []\n",
    "fund_dict['Industry/Vertical'] = []\n",
    "fund_dict['Sub-Vertical'] = []\n",
    "fund_dict['Location'] = []\n",
    "fund_dict['Investor'] = []\n",
    "fund_dict['Investment Type'] = []\n",
    "fund_dict['Amount(in USD)'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48,51):\n",
    "    driver.find_element_by_xpath('//div[@id=\"tablepress-{}_wrapper\"]/div/label/select/option[4]'.format(i)).click()\n",
    "\n",
    "    # Date\n",
    "    dt = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[2]'.format(i))\n",
    "    for d in dt:\n",
    "        fund_dict['Date'].append(d.text)\n",
    "\n",
    "    # Startup Name\n",
    "    sn = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[3]'.format(i))\n",
    "    for n in sn:\n",
    "        fund_dict['Startup Name'].append(n.text)\n",
    "    \n",
    "    # Industry/Vertical\n",
    "    ind = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[4]'.format(i))\n",
    "    for n in ind:\n",
    "        fund_dict['Industry/Vertical'].append(n.text)\n",
    "    \n",
    "    # Sub-Vertical\n",
    "    sv = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[5]'.format(i))\n",
    "    for s in sv:\n",
    "        fund_dict['Sub-Vertical'].append(s.text)\n",
    "\n",
    "    # Location\n",
    "    loc = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[6]'.format(i))\n",
    "    for l in loc:\n",
    "        fund_dict['Location'].append(l.text)\n",
    "    \n",
    "    # Investor\n",
    "    inv = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[7]'.format(i))\n",
    "    for n in inv:\n",
    "        fund_dict['Investor'].append(n.text)\n",
    "    \n",
    "    # Investment Type\n",
    "    invt = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[8]'.format(i))\n",
    "    for n in invt:\n",
    "        fund_dict['Investment Type'].append(n.text)\n",
    "    \n",
    "    # Amount\n",
    "    amt = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[9]'.format(i))\n",
    "    for a in amt:\n",
    "        fund_dict['Amount(in USD)'].append(a.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry/Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>Location</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Investment Type</th>\n",
       "      <th>Amount(in USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Walmart Inc</td>\n",
       "      <td>M&amp;A</td>\n",
       "      <td>1,200,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Vedantu</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Coatue Management</td>\n",
       "      <td>Series D</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Crio</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Learning Platform for Developers</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>021 Capital</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>934,160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>goDutch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Group Payments</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Matrix India,Y Combinator, Global Founders Cap...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Mystifly</td>\n",
       "      <td>Airfare Marketplace</td>\n",
       "      <td>Ticketing, Airline Retailing, and Post-Ticketi...</td>\n",
       "      <td>Singapore and Bangalore</td>\n",
       "      <td>Recruit Co. Ltd.</td>\n",
       "      <td>pre-Series B</td>\n",
       "      <td>3,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>JetSynthesys</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Adar Poonawalla and Kris Gopalakrishnan.</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10/07/2020</td>\n",
       "      <td>gigIndia</td>\n",
       "      <td>Marketplace</td>\n",
       "      <td>Crowd Sourcing, Freelance</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Incubate Fund India and Beyond Next Ventures</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>974,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>PumPumPum</td>\n",
       "      <td>Automotive Rental</td>\n",
       "      <td>Used Car-leasing platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Early Adapters Syndicate</td>\n",
       "      <td>Seed</td>\n",
       "      <td>292,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>FLYX</td>\n",
       "      <td>OTT Player</td>\n",
       "      <td>Streaming Social Network</td>\n",
       "      <td>New York and Delhi</td>\n",
       "      <td>Raj Mishra, founder of AIT Global Inc</td>\n",
       "      <td>pre-Seed</td>\n",
       "      <td>200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Open Appliances Pvt. Ltd.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Internet-of-Things Security Solutions</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Unicorn India Ventures</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15/08/2020</td>\n",
       "      <td>Practo</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>Health care and Wellness</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>A1A Company</td>\n",
       "      <td>Series F</td>\n",
       "      <td>32,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Medlife</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Prasid Uno Family Trust and SC Credit Fund</td>\n",
       "      <td></td>\n",
       "      <td>23,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>HungerBox</td>\n",
       "      <td>FoodTech</td>\n",
       "      <td>Online Food Delivery Service</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>One97, Sabre Partners Trust, Pratithi Investme...</td>\n",
       "      <td>Series D1</td>\n",
       "      <td>1,560,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>Hyper-local Logistics</td>\n",
       "      <td>Online Delivery Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Existing Backers</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>Terra.do</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Climate School, E-learning</td>\n",
       "      <td>Stanford, California,</td>\n",
       "      <td>Stanford Angels and Entrepreneurs (India), BEE...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12/08/2020</td>\n",
       "      <td>Classplus</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>E-learning, Online Tutoring</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Falcon Edge</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>upto 15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14/08/2020</td>\n",
       "      <td>Niyo</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Niyo Solutions Inc.</td>\n",
       "      <td></td>\n",
       "      <td>6,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10/08/2020</td>\n",
       "      <td>ZestMoney</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Primrose Hills Ventures</td>\n",
       "      <td></td>\n",
       "      <td>10,670,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>07/08/2020</td>\n",
       "      <td>FreshToHome</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Food Delivery</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Ascent Capital</td>\n",
       "      <td>Venture</td>\n",
       "      <td>16,200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Eduvanz</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sequoia India, Unitus</td>\n",
       "      <td>Series A</td>\n",
       "      <td>5,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>03/08/2020</td>\n",
       "      <td>CrowdPouch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Elina Investments Pvt. Ltd</td>\n",
       "      <td>Angel</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>DrinkPrime</td>\n",
       "      <td>Water Purification</td>\n",
       "      <td>Water Purification</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Sequoia Surge, ON Mauritius</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>2,880,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Byju’s</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Silver Lake, Tiger Global, General Atlantic an...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>500,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>mCaffeine</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Skincare &amp; Haircare</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Amicus Capital Private Equity I LLP, Amicus Ca...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Qshala</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Curiosity Platform for Kids</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Rainmatter Capital</td>\n",
       "      <td>Angel</td>\n",
       "      <td>370,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>Winzo</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kalaari Capital Partners, IndigoEdge Managemen...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>15,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Hippo Video</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Newark, Delaware, United States of Amercia</td>\n",
       "      <td>Alpha Wave Incubation, Exfinity Venture Partne...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>Melorra</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Jewelry Store</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Shadow Holdings, Lightbox.</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>upto 8,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>1mg</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Gaja Capital, Tata Capital, Partners Group</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>mfine</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>On-Demand Healthcare Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Caretech Pte Inc</td>\n",
       "      <td>Series B</td>\n",
       "      <td>5,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>Apna</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Recruitment Platform</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Lightspeed India and Sequoia Capital India</td>\n",
       "      <td>Series A</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>03/09/2020</td>\n",
       "      <td>Railofy</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>WL &amp; RAC protection platform</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Chiratae Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>950,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Cell Propulsion</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Electric Mobility Solutions</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>growX Ventures and Micelio</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date               Startup Name  \\\n",
       "0   15/07/2020                   Flipkart   \n",
       "1   16/07/2020                    Vedantu   \n",
       "2   16/07/2020                       Crio   \n",
       "3   14/07/2020                    goDutch   \n",
       "4   13/07/2020                   Mystifly   \n",
       "5   09/07/2020               JetSynthesys   \n",
       "6   10/07/2020                   gigIndia   \n",
       "7   15/07/2020                  PumPumPum   \n",
       "8   14/07/2020                       FLYX   \n",
       "9   13/07/2020  Open Appliances Pvt. Ltd.   \n",
       "10  15/08/2020                     Practo   \n",
       "11  13/08/2020                    Medlife   \n",
       "12  13/08/2020                  HungerBox   \n",
       "13  04/08/2020                      Dunzo   \n",
       "14  11/08/2020                   Terra.do   \n",
       "15  12/08/2020                  Classplus   \n",
       "16  14/08/2020                       Niyo   \n",
       "17  10/08/2020                  ZestMoney   \n",
       "18  07/08/2020                FreshToHome   \n",
       "19  13/08/2020                    Eduvanz   \n",
       "20  03/08/2020                 CrowdPouch   \n",
       "21  04/08/2020                 DrinkPrime   \n",
       "22  08/09/2020                     Byju’s   \n",
       "23  12/09/2020                  mCaffeine   \n",
       "24  09/09/2020                     Qshala   \n",
       "25  02/09/2020                      Winzo   \n",
       "26  09/09/2020                Hippo Video   \n",
       "27  07/09/2020                    Melorra   \n",
       "28  07/09/2020                        1mg   \n",
       "29  31/08/2020                      mfine   \n",
       "30  31/08/2020                       Apna   \n",
       "31  03/09/2020                    Railofy   \n",
       "32  08/09/2020            Cell Propulsion   \n",
       "\n",
       "                         Industry/Vertical  \\\n",
       "0                               E-commerce   \n",
       "1                                  EduTech   \n",
       "2                                  EduTech   \n",
       "3                                  FinTech   \n",
       "4                      Airfare Marketplace   \n",
       "5                 Gaming and Entertainment   \n",
       "6                              Marketplace   \n",
       "7                        Automotive Rental   \n",
       "8                               OTT Player   \n",
       "9                   Information Technology   \n",
       "10                              HealthTech   \n",
       "11                              E-commerce   \n",
       "12                                FoodTech   \n",
       "13                   Hyper-local Logistics   \n",
       "14                                 EduTech   \n",
       "15                                 EduTech   \n",
       "16                                 FinTech   \n",
       "17                                 FinTech   \n",
       "18                              E-commerce   \n",
       "19                                 FinTech   \n",
       "20                                 FinTech   \n",
       "21                      Water Purification   \n",
       "22                                 EduTech   \n",
       "23                           Personal Care   \n",
       "24                                 EduTech   \n",
       "25                           Online Gaming   \n",
       "26  Video Customer Experience(CX) Platform   \n",
       "27                              E-commerce   \n",
       "28                              E-commerce   \n",
       "29                              HealthTech   \n",
       "30                         Human Resources   \n",
       "31                          Transportation   \n",
       "32                              Automobile   \n",
       "\n",
       "                                         Sub-Vertical  \\\n",
       "0                                          E-commerce   \n",
       "1                                     Online Tutoring   \n",
       "2                    Learning Platform for Developers   \n",
       "3                                      Group Payments   \n",
       "4   Ticketing, Airline Retailing, and Post-Ticketi...   \n",
       "5                            Gaming and Entertainment   \n",
       "6                           Crowd Sourcing, Freelance   \n",
       "7                           Used Car-leasing platform   \n",
       "8                            Streaming Social Network   \n",
       "9               Internet-of-Things Security Solutions   \n",
       "10                           Health care and Wellness   \n",
       "11                                    Online Pharmacy   \n",
       "12                       Online Food Delivery Service   \n",
       "13                           Online Delivery Services   \n",
       "14                  Online Climate School, E-learning   \n",
       "15                        E-learning, Online Tutoring   \n",
       "16                                 Financial Services   \n",
       "17                                 Financial Services   \n",
       "18                                      Food Delivery   \n",
       "19                                 Financial Services   \n",
       "20                                 Financial Services   \n",
       "21                                 Water Purification   \n",
       "22                                    Online Tutoring   \n",
       "23                                Skincare & Haircare   \n",
       "24                 Online Curiosity Platform for Kids   \n",
       "25                                      Online Gaming   \n",
       "26             Video Customer Experience(CX) Platform   \n",
       "27                               Online Jewelry Store   \n",
       "28                                    Online Pharmacy   \n",
       "29                      On-Demand Healthcare Services   \n",
       "30                               Recruitment Platform   \n",
       "31                       WL & RAC protection platform   \n",
       "32                        Electric Mobility Solutions   \n",
       "\n",
       "                                      Location  \\\n",
       "0                                    Bangalore   \n",
       "1                                    Bangalore   \n",
       "2                                    Bangalore   \n",
       "3                                       Mumbai   \n",
       "4                      Singapore and Bangalore   \n",
       "5                                         Pune   \n",
       "6                                         Pune   \n",
       "7                                      Gurgaon   \n",
       "8                           New York and Delhi   \n",
       "9                                    Bangalore   \n",
       "10                                   Bangalore   \n",
       "11                                   Bangalore   \n",
       "12                                   Bangalore   \n",
       "13                                   Bangalore   \n",
       "14                       Stanford, California,   \n",
       "15                                       Noida   \n",
       "16                                   Bangalore   \n",
       "17                                   Bangalore   \n",
       "18                                   Bangalore   \n",
       "19                                      Mumbai   \n",
       "20                                   Bangalore   \n",
       "21                                   Bangalore   \n",
       "22                                   Bangalore   \n",
       "23                                      Mumbai   \n",
       "24                                   Bangalore   \n",
       "25                                   New Delhi   \n",
       "26  Newark, Delaware, United States of Amercia   \n",
       "27                                   Bangalore   \n",
       "28                                     Gurgaon   \n",
       "29                                   Bangalore   \n",
       "30                                   Bangalore   \n",
       "31                                      Mumbai   \n",
       "32                                   Bangalore   \n",
       "\n",
       "                                             Investor         Investment Type  \\\n",
       "0                                         Walmart Inc                     M&A   \n",
       "1                                   Coatue Management                Series D   \n",
       "2                                         021 Capital            pre-Series A   \n",
       "3   Matrix India,Y Combinator, Global Founders Cap...                    Seed   \n",
       "4                                    Recruit Co. Ltd.            pre-Series B   \n",
       "5            Adar Poonawalla and Kris Gopalakrishnan.  Venture-Series Unknown   \n",
       "6        Incubate Fund India and Beyond Next Ventures            pre-Series A   \n",
       "7                            Early Adapters Syndicate                    Seed   \n",
       "8               Raj Mishra, founder of AIT Global Inc                pre-Seed   \n",
       "9                              Unicorn India Ventures  Venture-Series Unknown   \n",
       "10                                        A1A Company                Series F   \n",
       "11         Prasid Uno Family Trust and SC Credit Fund                           \n",
       "12  One97, Sabre Partners Trust, Pratithi Investme...               Series D1   \n",
       "13                                   Existing Backers             In Progress   \n",
       "14  Stanford Angels and Entrepreneurs (India), BEE...                    Seed   \n",
       "15                                        Falcon Edge             In Progress   \n",
       "16                                Niyo Solutions Inc.                           \n",
       "17                            Primrose Hills Ventures                           \n",
       "18                                     Ascent Capital                 Venture   \n",
       "19                              Sequoia India, Unitus                Series A   \n",
       "20                         Elina Investments Pvt. Ltd                   Angel   \n",
       "21                        Sequoia Surge, ON Mauritius            Pre-Series A   \n",
       "22  Silver Lake, Tiger Global, General Atlantic an...          Private Equity   \n",
       "23  Amicus Capital Private Equity I LLP, Amicus Ca...                Series B   \n",
       "24                                 Rainmatter Capital                   Angel   \n",
       "25  Kalaari Capital Partners, IndigoEdge Managemen...                Series B   \n",
       "26  Alpha Wave Incubation, Exfinity Venture Partne...                Series A   \n",
       "27                         Shadow Holdings, Lightbox.          Debt Financing   \n",
       "28         Gaja Capital, Tata Capital, Partners Group             In Progress   \n",
       "29                                   Caretech Pte Inc                Series B   \n",
       "30         Lightspeed India and Sequoia Capital India                Series A   \n",
       "31                                  Chiratae Ventures                    Seed   \n",
       "32                         growX Ventures and Micelio            pre-Series A   \n",
       "\n",
       "     Amount(in USD)  \n",
       "0     1,200,000,000  \n",
       "1       100,000,000  \n",
       "2           934,160  \n",
       "3         1,700,000  \n",
       "4         3,300,000  \n",
       "5           400,000  \n",
       "6           974,200  \n",
       "7           292,800  \n",
       "8           200,000  \n",
       "9           500,000  \n",
       "10       32,000,000  \n",
       "11       23,000,000  \n",
       "12        1,560,000  \n",
       "13       30,000,000  \n",
       "14        1,400,000  \n",
       "15  upto 15,000,000  \n",
       "16        6,000,000  \n",
       "17       10,670,000  \n",
       "18       16,200,000  \n",
       "19        5,000,000  \n",
       "20               NA  \n",
       "21        2,880,000  \n",
       "22      500,000,000  \n",
       "23        3,000,000  \n",
       "24          370,000  \n",
       "25       15,500,000  \n",
       "26        4,500,000  \n",
       "27   upto 8,900,000  \n",
       "28      100,000,000  \n",
       "29        5,400,000  \n",
       "30        8,000,000  \n",
       "31          950,000  \n",
       "32               NA  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(fund_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Trak investment.csv\",index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7.Write a program to scrap all the available details of top 10 gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.digit.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSelectorException",
     "evalue": "Message: invalid selector: Unable to locate an element with the xpath expression //ul[@id='top10list']/li[2]'] because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '//ul[@id='top10list']/li[2]']' is not a valid XPath expression.\n  (Session info: chrome=88.0.4324.146)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-5c5d977aea3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#clicking on laptops option\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlaptops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//ul[@id='top10list']/li[2]']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mlaptops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#best gaming laptops link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidSelectorException\u001b[0m: Message: invalid selector: Unable to locate an element with the xpath expression //ul[@id='top10list']/li[2]'] because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '//ul[@id='top10list']/li[2]']' is not a valid XPath expression.\n  (Session info: chrome=88.0.4324.146)\n"
     ]
    }
   ],
   "source": [
    "#clickng on top 10 option \n",
    "top_10=driver.find_element_by_xpath(\"//div[@class='menu']/ul/li[3]/a\")\n",
    "top_10.click()\n",
    "\n",
    "#clicking on laptops option\n",
    "laptops=driver.find_element_by_xpath(\"//ul[@id='top10list']/li[2]']\")\n",
    "laptops.click()\n",
    "#best gaming laptops link\n",
    "best_gaming=driver.find_element_by_xpath(\"//div[@id='laptops']/a[3]\")\n",
    "driver.get(best_gaming.get_attribute('href'))\n",
    "\n",
    "#intialising lists\n",
    "name = []\n",
    "price = []\n",
    "OS = []\n",
    "display = []\n",
    "processor = []\n",
    "HDD = []\n",
    "RAM = []\n",
    "weight = []\n",
    "dimension = []\n",
    "GPU = []\n",
    "\n",
    "#names\n",
    "names=driver.find_elements_by_xpath(\"//div[@class='right-container']/div/a/h3\")\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "#os\n",
    "os=driver.find_elements_by_xpath(\"//div[@class='product-detail']/div/ul/li[1]/div/div\")\n",
    "for i in os:\n",
    "    OS.append(i.text)\n",
    "    \n",
    "#display\n",
    "displays=driver.find_elements_by_xpath(\"//div[@class='product-detail']/div/ul/li[2]/div/div\")\n",
    "for i in displays:\n",
    "    display.append(i.text)\n",
    "    \n",
    "#processor\n",
    "processors=driver.find_elements_by_xpath(\"//div[@class='product-detail']/div/ul/li[3]/div/div\")\n",
    "for i in processors:\n",
    "    processor.append(i.text)\n",
    "processor\n",
    "\n",
    "#memory\n",
    "memories=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[6]/td[1]\")#list of specificaion name\n",
    "memories_spec=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[6]/td[3]\")#values of specifiations \n",
    "for i in range(len(memories)):\n",
    "        if memories[i].text=='Memory':\n",
    "            HDD.append(memories_spec[i].text.split('/')[0])\n",
    "            RAM.append(memories_spec[i].text.split('/')[1])\n",
    "        else:\n",
    "            HDD.append('No details available')#append no details as value for memory is missing in some of the laptops\n",
    "            RAM.append('No details available')#append no details as value for memory is missing in some of the laptops\n",
    "\n",
    "#weight\n",
    "weights=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr/td[1]\")#list of specificaion name\n",
    "weight_spec=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr/td[3]\")#values of specifiations\n",
    "for i in range(len(weights)):\n",
    "        if weights[i].text=='Weight':\n",
    "            weight.append(weight_spec[i].text)\n",
    "        \n",
    "#dimension\n",
    "dimension=[]\n",
    "dims=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr/td[1]\")#list of specificaion name\n",
    "dims_spec=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr/td[3]\")#values of specifiations\n",
    "for i in range(len(dims)):\n",
    "        if dims[i].text=='Dimension':\n",
    "            dimension.append(dims_spec[i].text)\n",
    "\n",
    "#graphical processor\n",
    "GPUs=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr/td[1]\")#list of specificaion name\n",
    "GPUs_spec=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr/td[3]\")#values of specifiations\n",
    "for i in range(len(GPUs)):\n",
    "        if GPUs[i].text=='Graphics Processor':\n",
    "            GPU.append(GPUs_spec[i].text)\n",
    "        \n",
    "full_specs=[]\n",
    "urls=driver.find_elements_by_xpath(\"//div[@class='full-specs']/span\")#getting the url of full specs links\n",
    "for i in urls:\n",
    "    if i.get_attribute('data-href'):\n",
    "        full_specs.append(i.get_attribute('data-href'))\n",
    "    \n",
    "for i in full_specs:#iterating throug every laptops full specs' page\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prices=driver.find_element_by_xpath(\"//div[@class='Block-price']/b\")\n",
    "        price.append(prices.text)\n",
    "    except NoSuchElementException:#exception handling for no price details\n",
    "        price.append(\"No details available\")\n",
    "        \n",
    "df=pd.DataFrame({\"Name\":name,\n",
    "                \"Price\":price,\n",
    "                \"OS\":OS,\n",
    "                \"Display\":display,\n",
    "                \"HDD\":HDD,\n",
    "                 \"RAM\":RAM,\n",
    "                \"processor\":processor,\n",
    "                \"weight\":weight,\n",
    "                \"Dimension\":dimension,\n",
    "                \"Graphical processor\":GPU})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
